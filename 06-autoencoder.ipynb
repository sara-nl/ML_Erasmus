{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical session we will answer questions about autoencoders and build one that compresses and reconstructs Fashion MNIST items.\n",
    "\n",
    "![](images/autoencoder_schema.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-encoders learn a *data-specific* compression function in an unsupervised manner. Depending on model complexity, autoencoders can generate very realistic reconstructions, but are always **lossy**. That is, some information about the original image will be lost.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-encoders are unsupervised. This is a very useful property. Why do you think so?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can use **any** raw dataset we have and encode it without collecting labels whatsoever. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, an autoencoder can be denoted as follows:\n",
    "\n",
    "$$\\hat{x} = d(e(x)) = d(z)$$\n",
    "\n",
    "That is, it consists of an encoding function $e(x)$, a decoding function $d(z)$, where $z \\in \\mathbb{R}^d$ is some compressed state of $x$. Note that in all previous sessions we denoted our model output as $\\hat{y}$. This time we do not, since our metric function will be one that compares $\\hat{x}$ (our reconstructed image) to $x$ (the original image) instead of a target vector $y$.\n",
    "\n",
    "If we parameterize $d$ and $e$ as neural networks, and use some differentiable loss function that compares the quality of the original input to the reconstructed input, we can simply use backpropagation to optimize!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoders are mainly used for three tasks:\n",
    "\n",
    "* If we add stochasticity (Variational Auto Encoder) we can sample new datapoints.\n",
    "* We can visualize our data distribution more clearly using the compressed representation. Simpler algorithms (T-SNE, PCA) might fall short here.\n",
    "\n",
    "![](images/compression.png)\n",
    "* We can use it for denoising our data, which we will do in this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following picture shows an autoencoder in the style that we visualized neural networks before.\n",
    "\n",
    "![](images/autoencoder_neurons.png)\n",
    "\n",
    "Let's build one using keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)\n",
    "source(\"06-helpers.R\")\n",
    "\n",
    "use_multi_cpu()\n",
    "\n",
    "data <- dataset_fashion_mnist()\n",
    "data_train <- data$train\n",
    "data_test <- data$test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the preprocessing. Note that we don't need the labels this time. Try to do the following steps with the dataset:\n",
    "\n",
    "* Extract the training and testing images.\n",
    "* Normalize them.\n",
    "* Part a slice of the training data for validation.\n",
    "\n",
    "If you can't remember how to do these steps, try looking at notebook 03b!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "<YOUR ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with constructing the autoencoder model. As can be seen from the previous image, an autoencoder can be constructed using a single sequence of operations. \n",
    "\n",
    "This time, we only provide the bare skeleton of the model. Try using hidden dimensions of 8 neurons and a latent dimension (that is, the dimensionality of the vector that the encoder outputs) of 4 neurons. Use ReLU activation for the intermediate layers, and sigmoid activation at the final output.\n",
    "\n",
    "Why do you think we need sigmoid activation at the end?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- keras_model_sequential() %>%\n",
    "    <FILL IN>\n",
    "\n",
    "cat(summary(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What makes up the difference between the encoding parameters and the decoding parameters?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<YOUR ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compile the model. Use `adam` as the optimizer with learning rate `0.01`. Next, use the `binary_crossentropy` loss function. That is, we treat every output neuron as a Bernoulli distribution with parameter $p$ and compare the original an reconstructed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model %>% compile(\n",
    "    <FILL IN>\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history <- model %>% fit(\n",
    "    x = x_train,\n",
    "    y = x_train,\n",
    "    validation_data = list(x_val, x_val),\n",
    "    epochs = 80,\n",
    "    batch_size = 4096,\n",
    "    callbacks=list(Progress$new())\n",
    ")\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict <- x_test[1:10,]\n",
    "\n",
    "predictions <- model %>% predict(to_predict, batch_size = 1)\n",
    "predictions <- array_reshape(predictions, c(10, 28, 28))\n",
    "\n",
    "index <- 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change this index to compare different images.\n",
    "\n",
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "\n",
    "options(repr.plot.width = 3, repr.plot.height = 3)\n",
    "ggplot(melt(t(apply(array_reshape(to_predict[index,], c(28, 28)), 2, rev)), varnames=c('x', 'y')), aes(x=x, y=y, fill=value)) +\n",
    "    geom_raster() +\n",
    "    scale_x_continuous(expand = c(0, 0)) +\n",
    "    scale_y_continuous(expand = c(0, 0)) +\n",
    "    scale_fill_gradient(low=\"#000000\", high=\"#FFFFFF\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position = \"none\") +\n",
    "    ggtitle(paste('Label:', x_test[index]))\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "options(repr.plot.width = 3, repr.plot.height = 3)\n",
    "ggplot(melt(t(apply(predictions[index,,], 2, rev)), varnames=c('x', 'y')), aes(x=x, y=y, fill=value)) +\n",
    "    geom_raster() +\n",
    "    scale_x_continuous(expand = c(0, 0)) +\n",
    "    scale_y_continuous(expand = c(0, 0)) +\n",
    "    scale_fill_gradient(low=\"#000000\", high=\"#FFFFFF\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position = \"none\") +\n",
    "    ggtitle(paste('Label:', x_test[index]))\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the model is trying, but the reconstructions aren't of high quality... Try to beef up the network by increasing the amount of layers, layer sizes and latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- keras_model_sequential() %>%\n",
    "    <FILL IN>\n",
    "\n",
    "cat(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model %>% compile(\n",
    "    optimizer = optimizer_adam(lr = 0.01),\n",
    "    loss = \"binary_crossentropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history <- model %>% fit(\n",
    "    x = x_train,\n",
    "    y = x_train,\n",
    "    validation_data = list(x_val, x_val),\n",
    "    epochs = 80,\n",
    "    batch_size = 4096,\n",
    "    callbacks=list(Progress$new())\n",
    ")\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict <- x_test[1:10,]\n",
    "\n",
    "predictions <- model %>% predict(to_predict, batch_size = 1)\n",
    "predictions <- array_reshape(predictions, c(10, 28, 28))\n",
    "\n",
    "index <- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "options(repr.plot.width = 3, repr.plot.height = 3)\n",
    "ggplot(melt(t(apply(predictions[index,,], 2, rev)), varnames=c('x', 'y')), aes(x=x, y=y, fill=value)) +\n",
    "    geom_raster() +\n",
    "    scale_x_continuous(expand = c(0, 0)) +\n",
    "    scale_y_continuous(expand = c(0, 0)) +\n",
    "    scale_fill_gradient(low=\"#000000\", high=\"#FFFFFF\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position = \"none\") +\n",
    "    ggtitle(paste('Label:', x_test[index]))\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks a bit better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoders can be used to denoise data. 'Noise' can be loosely interpreted. In fact, we can alter the original data with almost any transformation and recover the originals. For example, you could manually turn colored images into grayscale, and train an autoencoder to reverse this. After the model has converged, you could use the model to colorize old grayscale photos!\n",
    "\n",
    "Since we are dealing with grayscale data here, we will focus on denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Gaussian noise vectors for train, validation and test using the `rnorm` function. Use a standard deviation of 1. Reshape these vectors into the same shape as train, validation and test data using `array_reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_train <- <FILL_IN>\n",
    "noise_val <- <FILL_IN>\n",
    "noise_test <- <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy <- x_train + noise_train\n",
    "x_val_noisy <- x_val + noise_val\n",
    "x_test_noisy <- x_test + noise_test\n",
    "\n",
    "# We make sure max and min values are within the valid image range.\n",
    "x_train_noisy[x_train_noisy > 1] = 1\n",
    "x_train_noisy[x_train_noisy < 0] = 0\n",
    "\n",
    "x_val_noisy[x_val_noisy > 1] = 1\n",
    "x_val_noisy[x_val_noisy < 0] = 0\n",
    "\n",
    "x_test_noisy[x_test_noisy > 1] = 1\n",
    "x_test_noisy[x_test_noisy < 0] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a denoising autoencoder model. You could use the same architecture as in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- keras_model_sequential() %>%\n",
    "    <FILL IN>\n",
    "\n",
    "cat(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model %>% compile(\n",
    "    optimizer = optimizer_adam(lr = 0.01),\n",
    "    loss = \"binary_crossentropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history <- model %>% fit(\n",
    "    x = x_train_noisy,\n",
    "    y = x_train,\n",
    "    validation_data = list(x_val_noisy, x_val),\n",
    "    epochs = 80,\n",
    "    batch_size = 4096,\n",
    "    callbacks=list(Progress$new())\n",
    ")\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict <- x_test_noisy[1:10,]\n",
    "\n",
    "predictions <- model %>% predict(to_predict, batch_size = 1)\n",
    "predictions <- array_reshape(predictions, c(10, 28, 28))\n",
    "\n",
    "index <- 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "\n",
    "options(repr.plot.width = 3, repr.plot.height = 3)\n",
    "ggplot(melt(t(apply(array_reshape(to_predict[index,], c(28, 28)), 2, rev)), varnames=c('x', 'y')), aes(x=x, y=y, fill=value)) +\n",
    "    geom_raster() +\n",
    "    scale_x_continuous(expand = c(0, 0)) +\n",
    "    scale_y_continuous(expand = c(0, 0)) +\n",
    "    scale_fill_gradient(low=\"#000000\", high=\"#FFFFFF\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position = \"none\") +\n",
    "    ggtitle(paste('Label:', x_test[index]))\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "options(repr.plot.width = 3, repr.plot.height = 3)\n",
    "ggplot(melt(t(apply(predictions[index,,], 2, rev)), varnames=c('x', 'y')), aes(x=x, y=y, fill=value)) +\n",
    "    geom_raster() +\n",
    "    scale_x_continuous(expand = c(0, 0)) +\n",
    "    scale_y_continuous(expand = c(0, 0)) +\n",
    "    scale_fill_gradient(low=\"#000000\", high=\"#FFFFFF\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position = \"none\") +\n",
    "    ggtitle(paste('Label:', x_test[index]))\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've effectively removed the noise! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, this is partly due to the fact that our model is not complex enough to learn even the text on the shirt (index 2). In the bonus sections we will try to tackle this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bonus sections we will try to tackle this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1: Going convolutional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the presentations we have seen that convolutional neural networks (CNNs) can be extremely powerful for image data. Let's change our network by using convolutions and increasing the parameters to generate images of higher quality.\n",
    "\n",
    "\n",
    "First, we reshape the data such that it is compatible with a convolutional approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train <- array_reshape(x_train, c(48000, 28, 28, 1))\n",
    "x_val <- array_reshape(x_val, c(12000, 28, 28, 1))\n",
    "x_test <- array_reshape(x_test, c(10000, 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_train <- array_reshape(0.1 * rnorm(48000 * 28 * 28), c(48000, 28, 28, 1))\n",
    "noise_val <- array_reshape(0.1 * rnorm(12000 * 28 * 28), c(12000, 28, 28, 1))\n",
    "noise_test <- array_reshape(0.1 * rnorm(10000 * 28 * 28), c(10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy <- x_train + noise_train\n",
    "x_val_noisy <- x_val + noise_val\n",
    "x_test_noisy <- x_test + noise_test\n",
    "\n",
    "\n",
    "x_train_noisy[x_train_noisy > 1] = 1\n",
    "x_train_noisy[x_train_noisy < 0] = 0\n",
    "\n",
    "x_val_noisy[x_val_noisy > 1] = 1\n",
    "x_val_noisy[x_val_noisy < 0] = 0\n",
    "\n",
    "x_test_noisy[x_test_noisy > 1] = 1\n",
    "x_test_noisy[x_test_noisy < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Convolutional Autoencoder model. Use two convolutional layers `layer_conv_2d` with 32 filters, kernel sizes of 3, 'SAME' padding and ReLU activation. After each convolutional layer use a `layer_average_pooling_2d` layer to reduce the spatial dimensionality. Then flatten the activations using `layer_flatten` and map to a dense vector with dimensionality 64. \n",
    "\n",
    "Try to 'mirror' the encoder into a decoder (e.g. the amount of layers and parameters should be roughly the same), using `layer_upsamlpling_2d` instead of average pooling.\n",
    "\n",
    "Your final layer should be a convolutional layer with 1 filter and sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn <- keras_model_sequential() %>%\n",
    "    <FILL IN>\n",
    "cat(summary(model_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn %>% compile(\n",
    "    optimizer = optimizer_adam(lr = 0.01),\n",
    "    loss = \"binary_crossentropy\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the 'heavy' network, we reduce epochs and batch size. ÃŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history <- model_cnn %>% fit(\n",
    "    x = x_train_noisy,\n",
    "    y = x_train,\n",
    "    validation_data = list(x_val_noisy, x_val),\n",
    "    epochs = 5,\n",
    "    batch_size = 64,\n",
    "    callbacks=list(Progress$new())\n",
    ")\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_predict <- array_reshape(x_test_noisy[1:10,,,], c(10, 28, 28, 1))\n",
    "predictions <- model_cnn %>% predict(to_predict, batch_size = 1)\n",
    "predictions <- array_reshape(predictions, c(10, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "index=4\n",
    "\n",
    "options(repr.plot.width = 3, repr.plot.height = 3)\n",
    "ggplot(melt(t(apply(to_predict[index,,,], 2, rev)), varnames=c('x', 'y')), aes(x=x, y=y, fill=value)) +\n",
    "    geom_raster() +\n",
    "    scale_x_continuous(expand = c(0, 0)) +\n",
    "    scale_y_continuous(expand = c(0, 0)) +\n",
    "    scale_fill_gradient(low=\"#000000\", high=\"#FFFFFF\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position = \"none\") +\n",
    "    ggtitle(paste('Label:', x_test[index]))\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "\n",
    "options(repr.plot.width = 3, repr.plot.height = 3)\n",
    "ggplot(melt(t(apply(predictions[index,,], 2, rev)), varnames=c('x', 'y')), aes(x=x, y=y, fill=value)) +\n",
    "    geom_raster() +\n",
    "    scale_x_continuous(expand = c(0, 0)) +\n",
    "    scale_y_continuous(expand = c(0, 0)) +\n",
    "    scale_fill_gradient(low=\"#000000\", high=\"#FFFFFF\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position = \"none\") +\n",
    "    ggtitle(paste('Label:', x_test[index]))\n",
    "options(repr.plot.width = 6, repr.plot.height = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice! This network could probably become much better if we weren't computationally constrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 2:\n",
    "\n",
    "Try using BatchNormalization to speed up training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
